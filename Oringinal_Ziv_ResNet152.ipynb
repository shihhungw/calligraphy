{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ziv ResNet152.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7hefzNdh-6zw",
        "TTLgmXC_vkVW"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing"
      ],
      "metadata": {
        "id": "7hefzNdh-6zw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55FRLNI24QOc",
        "outputId": "e3b04b23-466a-4661-d69d-d5bfea9061e5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Dec 25 16:12:43 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNIhm6fi3XJL",
        "outputId": "e4efddea-c558-44c2-807e-a3eedc0c0c30"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_end = 1600\n",
        "valid_end = 2000\n",
        "test_end  = 400"
      ],
      "metadata": {
        "id": "flPJFuz5pbri"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "train_x = []\n",
        "train_y = []\n",
        "\n",
        "p1 = '/content/drive/My Drive/ResNET/楷書/train'\n",
        "p2 = '/content/drive/My Drive/ResNET/行書/train'\n",
        "p3 = '/content/drive/My Drive/ResNET/隸書/train'\n",
        "\n",
        "\n",
        "for i in os.listdir(p1)[:train_end]:\n",
        "  img = cv2.imread(p1+'/'+i,cv2.IMREAD_COLOR)\n",
        "  img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)  # 將大小修改成250*250\n",
        "  train_x.append(img)\n",
        "  train_y.append(0)\n",
        "\n",
        "for i in os.listdir(p2)[:train_end]:\n",
        "  img = cv2.imread(p2+'/'+i,cv2.IMREAD_COLOR)\n",
        "  img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)  # 將大小修改成250*250\n",
        "  train_x.append(img)\n",
        "  train_y.append(1)\n",
        "\n",
        "for i in os.listdir(p3)[:train_end]:\n",
        "  img = cv2.imread(p3+'/'+i,cv2.IMREAD_COLOR)\n",
        "  img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)  # 將大小修改成250*250\n",
        "  train_x.append(img)\n",
        "  train_y.append(2)\n",
        "\n",
        "train_xx = np.array(train_x).reshape(len(train_x), 224, 224, 3)\n",
        "print(train_xx.shape) \n",
        "train_yy = np.array(train_y).reshape(len(train_y), 1)\n",
        "print(train_yy.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCW5CtyYJiIY",
        "outputId": "f4ae3fd2-ff7a-47b8-cb2d-b01d60243e8b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4800, 224, 224, 3)\n",
            "(4800, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_x = []\n",
        "val_y = []\n",
        "\n",
        "for i in os.listdir(p1)[train_end:valid_end]:\n",
        "  img = cv2.imread(p1+'/'+i,cv2.IMREAD_COLOR)\n",
        "  img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)  # 將大小修改成250*250\n",
        "  val_x.append(img)\n",
        "  val_y.append(0)\n",
        "\n",
        "for i in os.listdir(p2)[train_end:valid_end]:\n",
        "  img = cv2.imread(p2+'/'+i,cv2.IMREAD_COLOR)\n",
        "  img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)  # 將大小修改成250*250\n",
        "  val_x.append(img)\n",
        "  val_y.append(1)\n",
        "\n",
        "for i in os.listdir(p3)[train_end:valid_end]:\n",
        "  img = cv2.imread(p3+'/'+i,cv2.IMREAD_COLOR)\n",
        "  img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)  # 將大小修改成250*250\n",
        "  val_x.append(img)\n",
        "  val_y.append(2)\n",
        "\n",
        "val_xx = np.array(val_x).reshape(len(val_x), 224, 224, 3)\n",
        "print(val_xx.shape) \n",
        "val_yy = np.array(val_y).reshape(len(val_y), 1)\n",
        "print(val_yy.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgqYMWAPJrBe",
        "outputId": "fc0b4a1d-6791-4c7f-8dcc-26872ef21da9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1200, 224, 224, 3)\n",
            "(1200, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_x = []\n",
        "test_y = []\n",
        "\n",
        "p1 = '/content/drive/My Drive/ResNET/楷書/test'\n",
        "p2 = '/content/drive/My Drive/ResNET/行書/test'\n",
        "p3 = '/content/drive/My Drive/ResNET/隸書/test'\n",
        "\n",
        "for i in os.listdir(p1)[:test_end]:\n",
        "  img = cv2.imread(p1+'/'+i,cv2.IMREAD_COLOR)\n",
        "  img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)  # 將大小修改成250*250\n",
        "  test_x.append(img)\n",
        "  test_y.append(0)\n",
        "\n",
        "for i in os.listdir(p2)[:test_end]:\n",
        "  img = cv2.imread(p2+'/'+i,cv2.IMREAD_COLOR)\n",
        "  img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)  # 將大小修改成250*250\n",
        "  test_x.append(img)\n",
        "  test_y.append(1)\n",
        "\n",
        "for i in os.listdir(p3)[:test_end]:\n",
        "  img = cv2.imread(p3+'/'+i,cv2.IMREAD_COLOR)\n",
        "  img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)  # 將大小修改成250*250\n",
        "  test_x.append(img)\n",
        "  test_y.append(2)\n",
        "\n",
        "test_xx = np.array(test_x).reshape(len(test_x), 224, 224, 3)\n",
        "print(test_xx.shape) \n",
        "test_yy = np.array(test_y).reshape(len(test_y), 1)\n",
        "print(test_yy.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tepXiPQCJoKB",
        "outputId": "d7251e46-785a-44c8-848f-eb5fa4de1a75"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1200, 224, 224, 3)\n",
            "(1200, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_yy = np.eye(3)[train_yy.reshape(-1)]\n",
        "test_yy = np.eye(3)[test_yy.reshape(-1)]\n",
        "val_yy = np.eye(3)[val_yy.reshape(-1)]\n",
        "\n",
        "print(train_xx.shape)\n",
        "print(train_yy.shape)\n",
        "print(test_xx.shape)\n",
        "print(test_yy.shape)\n",
        "print(val_xx.shape)\n",
        "print(val_yy.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-TehJqGJt5N",
        "outputId": "5cffb3be-df09-427b-bbb0-a4c085de600e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4800, 224, 224, 3)\n",
            "(4800, 3)\n",
            "(1200, 224, 224, 3)\n",
            "(1200, 3)\n",
            "(1200, 224, 224, 3)\n",
            "(1200, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ResNET152"
      ],
      "metadata": {
        "id": "U7tXofdygBLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet152\n",
        "\n",
        "base_model_ResNet152 = ResNet152(weights = \"imagenet\", include_top=False, input_shape = (224,224, 3))\n",
        "#base_model_ResNet152 = ResNet152(weights = None, include_top=False, input_shape = (224,224, 3))\n",
        "\n",
        "\n",
        "#for layer in base_model_ResNet152.layers[:415]: #515層 - 100層\n",
        "for layer in base_model_ResNet152.layers[:415]: #515層 - 100層\n",
        "   layer.trainable = False\n",
        "#base_model_ResNet152.summary()"
      ],
      "metadata": {
        "id": "m9CxDs82gEM_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d464ebd3-180c-46d8-d686-642ddfd352ea"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "234700800/234698864 [==============================] - 5s 0us/step\n",
            "234708992/234698864 [==============================] - 5s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(base_model_ResNet152.layers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xs06C1UCgUO-",
        "outputId": "57cc0b2f-a792-40be-ef89-7ce9ea5dbd69"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "515"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# use “get_layer” method to save the last layer of the network\n",
        "# save the output of the last layer to be the input of the next layer\n",
        "\n",
        "last_layer = base_model_ResNet152.get_layer('conv5_block3_out')\n",
        "last_output = last_layer.output\n",
        "\n",
        "# flatten the classifier input which is output of the last layer of VGG16 model\n",
        "\n",
        "x = Flatten()(last_output)"
      ],
      "metadata": {
        "id": "0kVkw_5ZgXFS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add a 64 unit FC layer and relu activation \n",
        "x = Dense(256, activation='relu', name='Dense_1')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "x = Dense(64, activation='relu', name='Dense_2')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# add our new softmax layer with 2 units\n",
        "x = Dense(3, activation='softmax', name='softmaxxxx')(x)\n",
        "\n",
        "# instantiate實例化 a new_model using keras’s Model class\n",
        "new_model = Model(inputs=base_model_ResNet152.input, outputs=x)\n",
        "# print the new_model summary\n",
        "#new_model.summary()"
      ],
      "metadata": {
        "id": "xtDe2wx5guYT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# self.model.optimizer.learning_rate\n",
        "from tensorflow import keras\n",
        "class print_lr(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    print(f'Epoch {epoch}, the optimizer state is {self.model.optimizer.get_config()}')\n",
        "\n",
        "'''\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "csv_logger = CSVLogger('curve_ResNet152.csv')\n",
        "\n",
        "\n",
        "mc = ModelCheckpoint(\n",
        "    os.path.join('./result_ResNet152', 'epoch_{epoch}.h5'),\n",
        "    verbose=2,\n",
        "    monitor = 'val_loss',\n",
        "    #monitor = 'val_accuracy',\n",
        "    save_freq=5*(train_xx.shape[0] // 64),\n",
        "    mode='min')\n",
        "'''"
      ],
      "metadata": {
        "id": "IbRtAJzjg9lz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "d23601ee-eb4f-4db7-de31-7488bd1653c9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\\ncsv_logger = CSVLogger('curve_ResNet152.csv')\\n\\n\\nmc = ModelCheckpoint(\\n    os.path.join('./result_ResNet152', 'epoch_{epoch}.h5'),\\n    verbose=2,\\n    monitor = 'val_loss',\\n    #monitor = 'val_accuracy',\\n    save_freq=5*(train_xx.shape[0] // 64),\\n    mode='min')\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr    = 0.0001 #0.0005, 0.00005\n",
        "decay = 1e-4   #1e-6\n",
        "\n",
        "num_epochs = 100\n",
        "batch_size = 32  #64, 128\n",
        "steps_per_epoch  = train_end // batch_size #4\n",
        "validation_steps = (valid_end - train_end) // batch_size #2"
      ],
      "metadata": {
        "id": "GWYlVsblk3eM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Using different Batch_size & Learning_rate"
      ],
      "metadata": {
        "id": "OEmLAfMReTKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paras = [(0.0001, 32), (0.0001, 64), (0.0005, 32), (0.0005, 64)]\n",
        "score = [[], [], [], []]\n",
        "diffr = [[], [], [], []]"
      ],
      "metadata": {
        "id": "79QUo4O6eUd9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint \n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "csv_file =[]\n",
        "ind = 0\n",
        "\n",
        "for lr,batch_size in paras:\n",
        "  print(lr, batch_size)\n",
        "  \n",
        "  csv_name    = 'ResNet152_with_' + str(lr) + '_' + str(batch_size) + '.csv'\n",
        "  folder_name = './result_' + str(lr) + '_' + str(batch_size)\n",
        "  filepath    = folder_name + '/' + 'model_' + str(lr) + '_' + str(batch_size) + '.h5'\n",
        "  model_name  = 'ResNet152_Model_' + str(lr) + '_' + str(batch_size) + '.h5'\n",
        "  csv_file.append(csv_name)\n",
        "\n",
        "  #開新的csv & 設定mc\n",
        "  csv_logger = CSVLogger(csv_name)\n",
        "  mc = ModelCheckpoint(\n",
        "    os.path.join(folder_name, 'epoch_{epoch}.h5'),\n",
        "    verbose=2,\n",
        "    monitor = 'val_loss',\n",
        "    save_freq=5*(train_xx.shape[0] // 64),\n",
        "    mode='min')\n",
        "\n",
        "  optimizer = tf.optimizers.Adam(learning_rate=lr,decay=decay)\n",
        "  new_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  checkpointer = ModelCheckpoint(filepath=filepath, verbose=1, save_best_only=True) #filepath保存模型的路徑\n",
        "  history = new_model.fit(train_xx, train_yy, batch_size=batch_size, epochs=num_epochs, callbacks=[mc, csv_logger, print_lr()], steps_per_epoch=steps_per_epoch, validation_data=(val_xx, val_yy), validation_steps=validation_steps, verbose=2, shuffle=True)\n",
        "\n",
        "  #計算結果\n",
        "  score[ind] = new_model.evaluate(test_xx, test_yy, verbose=0)\n",
        "  print('\\n', 'Test accuracy:', score[ind][1])\n",
        "  new_model.save(model_name)\n",
        "\n",
        "  #找出預測錯誤\n",
        "  result = new_model.predict(test_xx, use_multiprocessing=True)\n",
        "  ans = np.zeros((1200,3))\n",
        "  for i in range(1200):\n",
        "    temp = result[i]\n",
        "    val = np.where(temp==np.max(temp))\n",
        "    val = int(val[0][0])\n",
        "    ans[i][val] = 1\n",
        "  for i in range(1200):\n",
        "    if(np.array_equal(ans[i],test_yy[i]) == False):\n",
        "      diffr[ind].append(i)\n",
        "\n",
        "  ind += 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjTC8ioUsawe",
        "outputId": "77366726-121c-431d-e859-1f9245e58878"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0001 32\n",
            "Epoch 1/100\n",
            "Epoch 0, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 41s - loss: 0.2353 - accuracy: 0.9181 - val_loss: 0.0221 - val_accuracy: 0.9870 - 41s/epoch - 827ms/step\n",
            "Epoch 2/100\n",
            "Epoch 1, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0907 - accuracy: 0.9694 - val_loss: 0.0157 - val_accuracy: 0.9974 - 10s/epoch - 203ms/step\n",
            "Epoch 3/100\n",
            "Epoch 2, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0718 - accuracy: 0.9787 - val_loss: 0.0225 - val_accuracy: 0.9896 - 10s/epoch - 203ms/step\n",
            "Epoch 4/100\n",
            "Epoch 3, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0429 - accuracy: 0.9900 - val_loss: 0.0435 - val_accuracy: 0.9818 - 10s/epoch - 203ms/step\n",
            "Epoch 5/100\n",
            "Epoch 4, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0262 - accuracy: 0.9950 - val_loss: 0.0184 - val_accuracy: 0.9948 - 10s/epoch - 202ms/step\n",
            "Epoch 6/100\n",
            "Epoch 5, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0194 - accuracy: 0.9944 - val_loss: 0.0436 - val_accuracy: 0.9922 - 10s/epoch - 206ms/step\n",
            "Epoch 7/100\n",
            "Epoch 6, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0115 - accuracy: 0.9962 - val_loss: 0.0078 - val_accuracy: 1.0000 - 10s/epoch - 203ms/step\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: saving model to ./result_0.0001_32/epoch_8.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 14s - loss: 0.0144 - accuracy: 0.9956 - val_loss: 0.0341 - val_accuracy: 0.9896 - 14s/epoch - 281ms/step\n",
            "Epoch 9/100\n",
            "Epoch 8, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0085 - accuracy: 0.9987 - val_loss: 0.0304 - val_accuracy: 0.9922 - 10s/epoch - 202ms/step\n",
            "Epoch 10/100\n",
            "Epoch 9, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0091 - accuracy: 0.9981 - val_loss: 0.0219 - val_accuracy: 0.9896 - 10s/epoch - 203ms/step\n",
            "Epoch 11/100\n",
            "Epoch 10, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 0.9922 - 10s/epoch - 203ms/step\n",
            "Epoch 12/100\n",
            "Epoch 11, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 0.9948 - 10s/epoch - 203ms/step\n",
            "Epoch 13/100\n",
            "Epoch 12, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0096 - accuracy: 0.9981 - val_loss: 0.0077 - val_accuracy: 0.9974 - 10s/epoch - 203ms/step\n",
            "Epoch 14/100\n",
            "Epoch 13, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0082 - accuracy: 0.9987 - val_loss: 0.0168 - val_accuracy: 0.9922 - 10s/epoch - 203ms/step\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: saving model to ./result_0.0001_32/epoch_15.h5\n",
            "Epoch 14, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 14s - loss: 0.0071 - accuracy: 0.9994 - val_loss: 0.0364 - val_accuracy: 0.9896 - 14s/epoch - 280ms/step\n",
            "Epoch 16/100\n",
            "Epoch 15, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0421 - val_accuracy: 0.9844 - 10s/epoch - 203ms/step\n",
            "Epoch 17/100\n",
            "Epoch 16, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0090 - accuracy: 0.9975 - val_loss: 0.0304 - val_accuracy: 0.9870 - 10s/epoch - 202ms/step\n",
            "Epoch 18/100\n",
            "Epoch 17, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0574 - val_accuracy: 0.9818 - 10s/epoch - 202ms/step\n",
            "Epoch 19/100\n",
            "Epoch 18, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0096 - val_accuracy: 0.9974 - 10s/epoch - 202ms/step\n",
            "Epoch 20/100\n",
            "Epoch 19, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 11s - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0338 - val_accuracy: 0.9870 - 11s/epoch - 224ms/step\n",
            "Epoch 21/100\n",
            "Epoch 20, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0244 - val_accuracy: 0.9922 - 10s/epoch - 203ms/step\n",
            "Epoch 22/100\n",
            "Epoch 21, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0078 - accuracy: 0.9987 - val_loss: 0.0276 - val_accuracy: 0.9896 - 10s/epoch - 202ms/step\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: saving model to ./result_0.0001_32/epoch_23.h5\n",
            "Epoch 22, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 14s - loss: 0.0089 - accuracy: 0.9981 - val_loss: 0.0046 - val_accuracy: 1.0000 - 14s/epoch - 278ms/step\n",
            "Epoch 24/100\n",
            "Epoch 23, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0079 - accuracy: 0.9969 - val_loss: 9.3304e-04 - val_accuracy: 1.0000 - 10s/epoch - 203ms/step\n",
            "Epoch 25/100\n",
            "Epoch 24, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.0730 - val_accuracy: 0.9766 - 10s/epoch - 202ms/step\n",
            "Epoch 26/100\n",
            "Epoch 25, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0109 - accuracy: 0.9975 - val_loss: 0.0317 - val_accuracy: 0.9844 - 10s/epoch - 202ms/step\n",
            "Epoch 27/100\n",
            "Epoch 26, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0129 - val_accuracy: 0.9948 - 10s/epoch - 203ms/step\n",
            "Epoch 28/100\n",
            "Epoch 27, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.0120 - val_accuracy: 0.9974 - 10s/epoch - 202ms/step\n",
            "Epoch 29/100\n",
            "Epoch 28, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0070 - accuracy: 0.9987 - val_loss: 0.0054 - val_accuracy: 0.9974 - 10s/epoch - 203ms/step\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: saving model to ./result_0.0001_32/epoch_30.h5\n",
            "Epoch 29, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 14s - loss: 0.0067 - accuracy: 0.9987 - val_loss: 0.0279 - val_accuracy: 0.9896 - 14s/epoch - 275ms/step\n",
            "Epoch 31/100\n",
            "Epoch 30, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0656 - val_accuracy: 0.9766 - 10s/epoch - 202ms/step\n",
            "Epoch 32/100\n",
            "Epoch 31, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0064 - accuracy: 0.9975 - val_loss: 0.0726 - val_accuracy: 0.9740 - 10s/epoch - 202ms/step\n",
            "Epoch 33/100\n",
            "Epoch 32, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0062 - accuracy: 0.9987 - val_loss: 0.0034 - val_accuracy: 1.0000 - 10s/epoch - 203ms/step\n",
            "Epoch 34/100\n",
            "Epoch 33, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0070 - accuracy: 0.9975 - val_loss: 0.0120 - val_accuracy: 0.9974 - 10s/epoch - 202ms/step\n",
            "Epoch 35/100\n",
            "Epoch 34, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0062 - accuracy: 0.9994 - val_loss: 0.0568 - val_accuracy: 0.9818 - 10s/epoch - 203ms/step\n",
            "Epoch 36/100\n",
            "Epoch 35, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0308 - val_accuracy: 0.9896 - 10s/epoch - 202ms/step\n",
            "Epoch 37/100\n",
            "Epoch 36, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0133 - val_accuracy: 0.9948 - 10s/epoch - 203ms/step\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: saving model to ./result_0.0001_32/epoch_38.h5\n",
            "Epoch 37, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 14s - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.0358 - val_accuracy: 0.9844 - 14s/epoch - 278ms/step\n",
            "Epoch 39/100\n",
            "Epoch 38, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0130 - accuracy: 0.9956 - val_loss: 0.0212 - val_accuracy: 0.9948 - 10s/epoch - 203ms/step\n",
            "Epoch 40/100\n",
            "Epoch 39, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0157 - accuracy: 0.9956 - val_loss: 0.0532 - val_accuracy: 0.9766 - 10s/epoch - 203ms/step\n",
            "Epoch 41/100\n",
            "Epoch 40, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0073 - accuracy: 0.9987 - val_loss: 0.0758 - val_accuracy: 0.9714 - 10s/epoch - 203ms/step\n",
            "Epoch 42/100\n",
            "Epoch 41, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.2534 - val_accuracy: 0.9193 - 10s/epoch - 203ms/step\n",
            "Epoch 43/100\n",
            "Epoch 42, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0084 - accuracy: 0.9981 - val_loss: 0.0886 - val_accuracy: 0.9818 - 10s/epoch - 202ms/step\n",
            "Epoch 44/100\n",
            "Epoch 43, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.0246 - val_accuracy: 0.9896 - 10s/epoch - 202ms/step\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: saving model to ./result_0.0001_32/epoch_45.h5\n",
            "Epoch 44, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 14s - loss: 0.0112 - accuracy: 0.9975 - val_loss: 0.0222 - val_accuracy: 0.9948 - 14s/epoch - 277ms/step\n",
            "Epoch 46/100\n",
            "Epoch 45, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0751 - val_accuracy: 0.9766 - 10s/epoch - 203ms/step\n",
            "Epoch 47/100\n",
            "Epoch 46, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0604 - val_accuracy: 0.9792 - 10s/epoch - 203ms/step\n",
            "Epoch 48/100\n",
            "Epoch 47, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 0.9974 - 10s/epoch - 202ms/step\n",
            "Epoch 49/100\n",
            "Epoch 48, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0088 - val_accuracy: 0.9974 - 10s/epoch - 203ms/step\n",
            "Epoch 50/100\n",
            "Epoch 49, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0164 - val_accuracy: 0.9948 - 10s/epoch - 202ms/step\n",
            "Epoch 51/100\n",
            "Epoch 50, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.0291 - val_accuracy: 0.9922 - 10s/epoch - 203ms/step\n",
            "Epoch 52/100\n",
            "Epoch 51, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0268 - val_accuracy: 0.9922 - 10s/epoch - 202ms/step\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: saving model to ./result_0.0001_32/epoch_53.h5\n",
            "Epoch 52, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 14s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 0.9896 - 14s/epoch - 277ms/step\n",
            "Epoch 54/100\n",
            "Epoch 53, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 11s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 0.9974 - 11s/epoch - 224ms/step\n",
            "Epoch 55/100\n",
            "Epoch 54, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0329 - val_accuracy: 0.9896 - 10s/epoch - 202ms/step\n",
            "Epoch 56/100\n",
            "Epoch 55, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.0266 - val_accuracy: 0.9922 - 10s/epoch - 203ms/step\n",
            "Epoch 57/100\n",
            "Epoch 56, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0049 - accuracy: 0.9981 - val_loss: 0.0207 - val_accuracy: 0.9922 - 10s/epoch - 202ms/step\n",
            "Epoch 58/100\n",
            "Epoch 57, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.2389 - val_accuracy: 0.9375 - 10s/epoch - 202ms/step\n",
            "Epoch 59/100\n",
            "Epoch 58, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0254 - val_accuracy: 0.9922 - 10s/epoch - 202ms/step\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: saving model to ./result_0.0001_32/epoch_60.h5\n",
            "Epoch 59, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 14s - loss: 0.0102 - accuracy: 0.9981 - val_loss: 0.0344 - val_accuracy: 0.9922 - 14s/epoch - 276ms/step\n",
            "Epoch 61/100\n",
            "Epoch 60, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.0276 - val_accuracy: 0.9922 - 10s/epoch - 202ms/step\n",
            "Epoch 62/100\n",
            "Epoch 61, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0082 - accuracy: 0.9975 - val_loss: 0.0999 - val_accuracy: 0.9661 - 10s/epoch - 202ms/step\n",
            "Epoch 63/100\n",
            "Epoch 62, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.0430 - val_accuracy: 0.9818 - 10s/epoch - 202ms/step\n",
            "Epoch 64/100\n",
            "Epoch 63, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0166 - accuracy: 0.9944 - val_loss: 0.0105 - val_accuracy: 0.9948 - 10s/epoch - 203ms/step\n",
            "Epoch 65/100\n",
            "Epoch 64, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0120 - accuracy: 0.9956 - val_loss: 0.0150 - val_accuracy: 0.9948 - 10s/epoch - 202ms/step\n",
            "Epoch 66/100\n",
            "Epoch 65, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0191 - accuracy: 0.9937 - val_loss: 0.0223 - val_accuracy: 0.9922 - 10s/epoch - 203ms/step\n",
            "Epoch 67/100\n",
            "Epoch 66, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0076 - accuracy: 0.9981 - val_loss: 0.0132 - val_accuracy: 0.9974 - 10s/epoch - 203ms/step\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 00068: saving model to ./result_0.0001_32/epoch_68.h5\n",
            "Epoch 67, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 14s - loss: 0.0031 - accuracy: 0.9987 - val_loss: 0.0191 - val_accuracy: 0.9948 - 14s/epoch - 277ms/step\n",
            "Epoch 69/100\n",
            "Epoch 68, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0142 - accuracy: 0.9969 - val_loss: 0.0500 - val_accuracy: 0.9844 - 10s/epoch - 203ms/step\n",
            "Epoch 70/100\n",
            "Epoch 69, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.0451 - val_accuracy: 0.9870 - 10s/epoch - 203ms/step\n",
            "Epoch 71/100\n",
            "Epoch 70, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0433 - val_accuracy: 0.9870 - 10s/epoch - 202ms/step\n",
            "Epoch 72/100\n",
            "Epoch 71, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.0507 - val_accuracy: 0.9792 - 10s/epoch - 203ms/step\n",
            "Epoch 73/100\n",
            "Epoch 72, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 0.9922 - 10s/epoch - 202ms/step\n",
            "Epoch 74/100\n",
            "Epoch 73, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0061 - val_accuracy: 0.9974 - 10s/epoch - 203ms/step\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 00075: saving model to ./result_0.0001_32/epoch_75.h5\n",
            "Epoch 74, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 14s - loss: 0.0029 - accuracy: 0.9987 - val_loss: 0.0074 - val_accuracy: 0.9948 - 14s/epoch - 278ms/step\n",
            "Epoch 76/100\n",
            "Epoch 75, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 0.9948 - 10s/epoch - 203ms/step\n",
            "Epoch 77/100\n",
            "Epoch 76, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 11s - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.0080 - val_accuracy: 0.9948 - 11s/epoch - 224ms/step\n",
            "Epoch 78/100\n",
            "Epoch 77, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0135 - accuracy: 0.9975 - val_loss: 0.0092 - val_accuracy: 0.9974 - 10s/epoch - 202ms/step\n",
            "Epoch 79/100\n",
            "Epoch 78, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0046 - val_accuracy: 0.9974 - 10s/epoch - 203ms/step\n",
            "Epoch 80/100\n",
            "Epoch 79, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9922 - 10s/epoch - 202ms/step\n",
            "Epoch 81/100\n",
            "Epoch 80, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 9.2209e-04 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 0.9948 - 10s/epoch - 202ms/step\n",
            "Epoch 82/100\n",
            "Epoch 81, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.0264 - val_accuracy: 0.9896 - 10s/epoch - 202ms/step\n",
            "Epoch 83/100\n",
            "\n",
            "Epoch 00083: saving model to ./result_0.0001_32/epoch_83.h5\n",
            "Epoch 82, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 14s - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0228 - val_accuracy: 0.9870 - 14s/epoch - 278ms/step\n",
            "Epoch 84/100\n",
            "Epoch 83, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0498 - val_accuracy: 0.9792 - 10s/epoch - 202ms/step\n",
            "Epoch 85/100\n",
            "Epoch 84, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.0352 - val_accuracy: 0.9844 - 10s/epoch - 202ms/step\n",
            "Epoch 86/100\n",
            "Epoch 85, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0103 - val_accuracy: 0.9948 - 10s/epoch - 202ms/step\n",
            "Epoch 87/100\n",
            "Epoch 86, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0062 - accuracy: 0.9987 - val_loss: 0.0095 - val_accuracy: 0.9974 - 10s/epoch - 202ms/step\n",
            "Epoch 88/100\n",
            "Epoch 87, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 11s - loss: 0.0053 - accuracy: 0.9981 - val_loss: 8.9724e-04 - val_accuracy: 1.0000 - 11s/epoch - 223ms/step\n",
            "Epoch 89/100\n",
            "Epoch 88, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0229 - val_accuracy: 0.9922 - 10s/epoch - 203ms/step\n",
            "Epoch 90/100\n",
            "\n",
            "Epoch 00090: saving model to ./result_0.0001_32/epoch_90.h5\n",
            "Epoch 89, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 14s - loss: 0.0068 - accuracy: 0.9987 - val_loss: 0.0326 - val_accuracy: 0.9896 - 14s/epoch - 276ms/step\n",
            "Epoch 91/100\n",
            "Epoch 90, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 0.9948 - 10s/epoch - 202ms/step\n",
            "Epoch 92/100\n",
            "Epoch 91, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0225 - val_accuracy: 0.9922 - 10s/epoch - 202ms/step\n",
            "Epoch 93/100\n",
            "Epoch 92, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 8.7257e-04 - accuracy: 1.0000 - val_loss: 0.0207 - val_accuracy: 0.9922 - 10s/epoch - 203ms/step\n",
            "Epoch 94/100\n",
            "Epoch 93, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 0.9896 - 10s/epoch - 202ms/step\n",
            "Epoch 95/100\n",
            "Epoch 94, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 6.3877e-04 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9896 - 10s/epoch - 202ms/step\n",
            "Epoch 96/100\n",
            "Epoch 95, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 9.4889e-04 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9896 - 10s/epoch - 203ms/step\n",
            "Epoch 97/100\n",
            "Epoch 96, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.0178 - val_accuracy: 0.9922 - 10s/epoch - 203ms/step\n",
            "Epoch 98/100\n",
            "\n",
            "Epoch 00098: saving model to ./result_0.0001_32/epoch_98.h5\n",
            "Epoch 97, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 14s - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.0033 - val_accuracy: 0.9974 - 14s/epoch - 276ms/step\n",
            "Epoch 99/100\n",
            "Epoch 98, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0474 - val_accuracy: 0.9870 - 10s/epoch - 202ms/step\n",
            "Epoch 100/100\n",
            "Epoch 99, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 11s - loss: 6.3676e-04 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 0.9896 - 11s/epoch - 224ms/step\n",
            "\n",
            " Test accuracy: 0.95333331823349\n",
            "0.0001 64\n",
            "Epoch 1/100\n",
            "Epoch 0, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 35s - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0950 - val_accuracy: 0.9818 - 35s/epoch - 695ms/step\n",
            "Epoch 2/100\n",
            "Epoch 1, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.1375 - val_accuracy: 0.9740 - 18s/epoch - 365ms/step\n",
            "Epoch 3/100\n",
            "Epoch 2, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.0795 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "Epoch 4/100\n",
            "Epoch 3, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0069 - accuracy: 0.9987 - val_loss: 0.0693 - val_accuracy: 0.9883 - 18s/epoch - 364ms/step\n",
            "Epoch 5/100\n",
            "Epoch 4, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0027 - accuracy: 0.9987 - val_loss: 0.0620 - val_accuracy: 0.9896 - 18s/epoch - 365ms/step\n",
            "Epoch 6/100\n",
            "Epoch 5, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 21s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0644 - val_accuracy: 0.9896 - 21s/epoch - 413ms/step\n",
            "Epoch 7/100\n",
            "Epoch 6, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0558 - val_accuracy: 0.9922 - 18s/epoch - 365ms/step\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: saving model to ./result_0.0001_64/epoch_8.h5\n",
            "Epoch 7, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 23s - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0572 - val_accuracy: 0.9922 - 23s/epoch - 458ms/step\n",
            "Epoch 9/100\n",
            "Epoch 8, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0032 - accuracy: 0.9997 - val_loss: 0.0594 - val_accuracy: 0.9922 - 18s/epoch - 365ms/step\n",
            "Epoch 10/100\n",
            "Epoch 9, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0607 - val_accuracy: 0.9922 - 18s/epoch - 364ms/step\n",
            "Epoch 11/100\n",
            "Epoch 10, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 6.5852e-04 - accuracy: 0.9997 - val_loss: 0.0593 - val_accuracy: 0.9922 - 18s/epoch - 365ms/step\n",
            "Epoch 12/100\n",
            "Epoch 11, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 3.5396e-04 - accuracy: 1.0000 - val_loss: 0.0586 - val_accuracy: 0.9922 - 18s/epoch - 365ms/step\n",
            "Epoch 13/100\n",
            "Epoch 12, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 9.0159e-04 - accuracy: 0.9997 - val_loss: 0.0610 - val_accuracy: 0.9922 - 18s/epoch - 365ms/step\n",
            "Epoch 14/100\n",
            "Epoch 13, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0587 - val_accuracy: 0.9922 - 18s/epoch - 365ms/step\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: saving model to ./result_0.0001_64/epoch_15.h5\n",
            "Epoch 14, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 22s - loss: 9.0848e-04 - accuracy: 0.9997 - val_loss: 0.0607 - val_accuracy: 0.9909 - 22s/epoch - 437ms/step\n",
            "Epoch 16/100\n",
            "Epoch 15, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 7.7151e-04 - accuracy: 0.9997 - val_loss: 0.0598 - val_accuracy: 0.9909 - 18s/epoch - 365ms/step\n",
            "Epoch 17/100\n",
            "Epoch 16, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.0591 - val_accuracy: 0.9909 - 18s/epoch - 364ms/step\n",
            "Epoch 18/100\n",
            "Epoch 17, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 1.7174e-04 - accuracy: 1.0000 - val_loss: 0.0583 - val_accuracy: 0.9922 - 18s/epoch - 365ms/step\n",
            "Epoch 19/100\n",
            "Epoch 18, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.0607 - val_accuracy: 0.9922 - 18s/epoch - 365ms/step\n",
            "Epoch 20/100\n",
            "Epoch 19, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 1.3987e-04 - accuracy: 1.0000 - val_loss: 0.0611 - val_accuracy: 0.9909 - 18s/epoch - 364ms/step\n",
            "Epoch 21/100\n",
            "Epoch 20, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 8.1439e-04 - accuracy: 0.9994 - val_loss: 0.0630 - val_accuracy: 0.9909 - 18s/epoch - 365ms/step\n",
            "Epoch 22/100\n",
            "Epoch 21, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 1.7430e-04 - accuracy: 1.0000 - val_loss: 0.0621 - val_accuracy: 0.9909 - 18s/epoch - 364ms/step\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: saving model to ./result_0.0001_64/epoch_23.h5\n",
            "Epoch 22, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 22s - loss: 1.4138e-04 - accuracy: 1.0000 - val_loss: 0.0615 - val_accuracy: 0.9909 - 22s/epoch - 440ms/step\n",
            "Epoch 24/100\n",
            "Epoch 23, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0607 - val_accuracy: 0.9922 - 18s/epoch - 365ms/step\n",
            "Epoch 25/100\n",
            "Epoch 24, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0589 - val_accuracy: 0.9922 - 18s/epoch - 364ms/step\n",
            "Epoch 26/100\n",
            "Epoch 25, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 9.6227e-04 - accuracy: 0.9994 - val_loss: 0.0611 - val_accuracy: 0.9909 - 18s/epoch - 364ms/step\n",
            "Epoch 27/100\n",
            "Epoch 26, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 1.2356e-04 - accuracy: 1.0000 - val_loss: 0.0591 - val_accuracy: 0.9909 - 18s/epoch - 365ms/step\n",
            "Epoch 28/100\n",
            "Epoch 27, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 8.8032e-05 - accuracy: 1.0000 - val_loss: 0.0587 - val_accuracy: 0.9909 - 18s/epoch - 365ms/step\n",
            "Epoch 29/100\n",
            "Epoch 28, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 5.8173e-04 - accuracy: 0.9997 - val_loss: 0.0614 - val_accuracy: 0.9922 - 18s/epoch - 365ms/step\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: saving model to ./result_0.0001_64/epoch_30.h5\n",
            "Epoch 29, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 22s - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.0608 - val_accuracy: 0.9909 - 22s/epoch - 442ms/step\n",
            "Epoch 31/100\n",
            "Epoch 30, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 1.2721e-04 - accuracy: 1.0000 - val_loss: 0.0612 - val_accuracy: 0.9922 - 18s/epoch - 365ms/step\n",
            "Epoch 32/100\n",
            "Epoch 31, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0021 - accuracy: 0.9991 - val_loss: 0.0542 - val_accuracy: 0.9922 - 18s/epoch - 365ms/step\n",
            "Epoch 33/100\n",
            "Epoch 32, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 1.1621e-04 - accuracy: 1.0000 - val_loss: 0.0565 - val_accuracy: 0.9922 - 18s/epoch - 365ms/step\n",
            "Epoch 34/100\n",
            "Epoch 33, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0610 - val_accuracy: 0.9922 - 18s/epoch - 364ms/step\n",
            "Epoch 35/100\n",
            "Epoch 34, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 8.9127e-04 - accuracy: 0.9997 - val_loss: 0.0562 - val_accuracy: 0.9909 - 18s/epoch - 364ms/step\n",
            "Epoch 36/100\n",
            "Epoch 35, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 7.4925e-04 - accuracy: 0.9997 - val_loss: 0.0580 - val_accuracy: 0.9922 - 18s/epoch - 365ms/step\n",
            "Epoch 37/100\n",
            "Epoch 36, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 9.3215e-04 - accuracy: 0.9997 - val_loss: 0.0579 - val_accuracy: 0.9909 - 18s/epoch - 365ms/step\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: saving model to ./result_0.0001_64/epoch_38.h5\n",
            "Epoch 37, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 22s - loss: 1.0993e-04 - accuracy: 1.0000 - val_loss: 0.0578 - val_accuracy: 0.9922 - 22s/epoch - 438ms/step\n",
            "Epoch 39/100\n",
            "Epoch 38, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 8.2609e-04 - accuracy: 0.9997 - val_loss: 0.0584 - val_accuracy: 0.9922 - 18s/epoch - 365ms/step\n",
            "Epoch 40/100\n",
            "Epoch 39, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 8.2849e-04 - accuracy: 0.9997 - val_loss: 0.0567 - val_accuracy: 0.9909 - 18s/epoch - 365ms/step\n",
            "Epoch 41/100\n",
            "Epoch 40, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 3.0861e-04 - accuracy: 1.0000 - val_loss: 0.0570 - val_accuracy: 0.9909 - 18s/epoch - 364ms/step\n",
            "Epoch 42/100\n",
            "Epoch 41, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 1.4204e-04 - accuracy: 1.0000 - val_loss: 0.0565 - val_accuracy: 0.9909 - 18s/epoch - 364ms/step\n",
            "Epoch 43/100\n",
            "Epoch 42, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 5.5370e-04 - accuracy: 1.0000 - val_loss: 0.0758 - val_accuracy: 0.9896 - 18s/epoch - 365ms/step\n",
            "Epoch 44/100\n",
            "Epoch 43, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 8.5062e-04 - accuracy: 0.9997 - val_loss: 0.0819 - val_accuracy: 0.9896 - 18s/epoch - 365ms/step\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: saving model to ./result_0.0001_64/epoch_45.h5\n",
            "Epoch 44, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 22s - loss: 8.2091e-04 - accuracy: 0.9997 - val_loss: 0.0763 - val_accuracy: 0.9896 - 22s/epoch - 438ms/step\n",
            "Epoch 46/100\n",
            "Epoch 45, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 5.8189e-04 - accuracy: 0.9997 - val_loss: 0.0620 - val_accuracy: 0.9909 - 18s/epoch - 365ms/step\n",
            "Epoch 47/100\n",
            "Epoch 46, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0040 - accuracy: 0.9997 - val_loss: 0.5098 - val_accuracy: 0.9076 - 18s/epoch - 364ms/step\n",
            "Epoch 48/100\n",
            "Epoch 47, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0096 - accuracy: 0.9981 - val_loss: 0.1285 - val_accuracy: 0.9701 - 18s/epoch - 365ms/step\n",
            "Epoch 49/100\n",
            "Epoch 48, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0115 - accuracy: 0.9950 - val_loss: 0.3654 - val_accuracy: 0.9323 - 18s/epoch - 364ms/step\n",
            "Epoch 50/100\n",
            "Epoch 49, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 21s - loss: 0.0171 - accuracy: 0.9947 - val_loss: 6.6237 - val_accuracy: 0.5104 - 21s/epoch - 413ms/step\n",
            "Epoch 51/100\n",
            "Epoch 50, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.0743 - val_accuracy: 0.9896 - 18s/epoch - 365ms/step\n",
            "Epoch 52/100\n",
            "Epoch 51, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0577 - val_accuracy: 0.9909 - 18s/epoch - 365ms/step\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: saving model to ./result_0.0001_64/epoch_53.h5\n",
            "Epoch 52, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 22s - loss: 0.0037 - accuracy: 0.9984 - val_loss: 0.0824 - val_accuracy: 0.9831 - 22s/epoch - 441ms/step\n",
            "Epoch 54/100\n",
            "Epoch 53, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 7.7492e-04 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 0.9844 - 18s/epoch - 365ms/step\n",
            "Epoch 55/100\n",
            "Epoch 54, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0669 - val_accuracy: 0.9883 - 18s/epoch - 364ms/step\n",
            "Epoch 56/100\n",
            "Epoch 55, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0681 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "Epoch 57/100\n",
            "Epoch 56, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 8.7144e-04 - accuracy: 0.9997 - val_loss: 0.0673 - val_accuracy: 0.9896 - 18s/epoch - 365ms/step\n",
            "Epoch 58/100\n",
            "Epoch 57, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0574 - val_accuracy: 0.9883 - 18s/epoch - 364ms/step\n",
            "Epoch 59/100\n",
            "Epoch 58, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 5.2806e-04 - accuracy: 0.9997 - val_loss: 0.0596 - val_accuracy: 0.9883 - 18s/epoch - 364ms/step\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: saving model to ./result_0.0001_64/epoch_60.h5\n",
            "Epoch 59, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 22s - loss: 9.8663e-04 - accuracy: 0.9997 - val_loss: 0.0561 - val_accuracy: 0.9883 - 22s/epoch - 439ms/step\n",
            "Epoch 61/100\n",
            "Epoch 60, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 7.2068e-04 - accuracy: 1.0000 - val_loss: 0.0616 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "Epoch 62/100\n",
            "Epoch 61, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 2.3355e-04 - accuracy: 1.0000 - val_loss: 0.0631 - val_accuracy: 0.9870 - 18s/epoch - 365ms/step\n",
            "Epoch 63/100\n",
            "Epoch 62, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 5.7224e-04 - accuracy: 0.9997 - val_loss: 0.0646 - val_accuracy: 0.9870 - 18s/epoch - 365ms/step\n",
            "Epoch 64/100\n",
            "Epoch 63, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 1.6327e-04 - accuracy: 1.0000 - val_loss: 0.0639 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "Epoch 65/100\n",
            "Epoch 64, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 6.4108e-04 - accuracy: 0.9994 - val_loss: 0.0630 - val_accuracy: 0.9870 - 18s/epoch - 365ms/step\n",
            "Epoch 66/100\n",
            "Epoch 65, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 8.5363e-04 - accuracy: 0.9997 - val_loss: 0.0651 - val_accuracy: 0.9870 - 18s/epoch - 365ms/step\n",
            "Epoch 67/100\n",
            "Epoch 66, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 21s - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0673 - val_accuracy: 0.9870 - 21s/epoch - 413ms/step\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 00068: saving model to ./result_0.0001_64/epoch_68.h5\n",
            "Epoch 67, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 22s - loss: 5.7646e-04 - accuracy: 1.0000 - val_loss: 0.0673 - val_accuracy: 0.9870 - 22s/epoch - 438ms/step\n",
            "Epoch 69/100\n",
            "Epoch 68, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 1.1318e-04 - accuracy: 1.0000 - val_loss: 0.0678 - val_accuracy: 0.9870 - 18s/epoch - 365ms/step\n",
            "Epoch 70/100\n",
            "Epoch 69, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.0696 - val_accuracy: 0.9870 - 18s/epoch - 365ms/step\n",
            "Epoch 71/100\n",
            "Epoch 70, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 1.4624e-04 - accuracy: 1.0000 - val_loss: 0.0683 - val_accuracy: 0.9870 - 18s/epoch - 365ms/step\n",
            "Epoch 72/100\n",
            "Epoch 71, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.0689 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "Epoch 73/100\n",
            "Epoch 72, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.0688 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "Epoch 74/100\n",
            "Epoch 73, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 2.9021e-04 - accuracy: 1.0000 - val_loss: 0.0680 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 00075: saving model to ./result_0.0001_64/epoch_75.h5\n",
            "Epoch 74, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 22s - loss: 2.5090e-04 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 0.9883 - 22s/epoch - 442ms/step\n",
            "Epoch 76/100\n",
            "Epoch 75, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 3.2422e-04 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "Epoch 77/100\n",
            "Epoch 76, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 4.2622e-04 - accuracy: 0.9997 - val_loss: 0.0680 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "Epoch 78/100\n",
            "Epoch 77, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 8.9250e-04 - accuracy: 0.9997 - val_loss: 0.0671 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "Epoch 79/100\n",
            "Epoch 78, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 9.3392e-05 - accuracy: 1.0000 - val_loss: 0.0668 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "Epoch 80/100\n",
            "Epoch 79, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 3.9006e-04 - accuracy: 0.9997 - val_loss: 0.0687 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "Epoch 81/100\n",
            "Epoch 80, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0699 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "Epoch 82/100\n",
            "Epoch 81, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 7.6405e-04 - accuracy: 0.9997 - val_loss: 0.0698 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "Epoch 83/100\n",
            "\n",
            "Epoch 00083: saving model to ./result_0.0001_64/epoch_83.h5\n",
            "Epoch 82, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 22s - loss: 6.3314e-04 - accuracy: 0.9997 - val_loss: 0.0691 - val_accuracy: 0.9883 - 22s/epoch - 438ms/step\n",
            "Epoch 84/100\n",
            "Epoch 83, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 9.4694e-04 - accuracy: 0.9997 - val_loss: 0.0696 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "Epoch 85/100\n",
            "Epoch 84, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 5.3314e-04 - accuracy: 0.9997 - val_loss: 0.0712 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "Epoch 86/100\n",
            "Epoch 85, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 8.4253e-04 - accuracy: 0.9997 - val_loss: 0.0695 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "Epoch 87/100\n",
            "Epoch 86, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.0715 - val_accuracy: 0.9883 - 18s/epoch - 364ms/step\n",
            "Epoch 88/100\n",
            "Epoch 87, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 2.6071e-04 - accuracy: 1.0000 - val_loss: 0.0712 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "Epoch 89/100\n",
            "Epoch 88, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 8.7861e-05 - accuracy: 1.0000 - val_loss: 0.0714 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "Epoch 90/100\n",
            "\n",
            "Epoch 00090: saving model to ./result_0.0001_64/epoch_90.h5\n",
            "Epoch 89, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 22s - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0737 - val_accuracy: 0.9883 - 22s/epoch - 440ms/step\n",
            "Epoch 91/100\n",
            "Epoch 90, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 1.5963e-04 - accuracy: 1.0000 - val_loss: 0.0730 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "Epoch 92/100\n",
            "Epoch 91, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 2.0444e-04 - accuracy: 1.0000 - val_loss: 0.0719 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "Epoch 93/100\n",
            "Epoch 92, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 3.7181e-04 - accuracy: 0.9997 - val_loss: 0.0706 - val_accuracy: 0.9883 - 18s/epoch - 364ms/step\n",
            "Epoch 94/100\n",
            "Epoch 93, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 8.8890e-04 - accuracy: 0.9994 - val_loss: 0.0713 - val_accuracy: 0.9896 - 18s/epoch - 364ms/step\n",
            "Epoch 95/100\n",
            "Epoch 94, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 2.8704e-04 - accuracy: 1.0000 - val_loss: 0.0704 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "Epoch 96/100\n",
            "Epoch 95, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 7.9053e-05 - accuracy: 1.0000 - val_loss: 0.0705 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "Epoch 97/100\n",
            "Epoch 96, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 8.4913e-05 - accuracy: 1.0000 - val_loss: 0.0704 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "Epoch 98/100\n",
            "\n",
            "Epoch 00098: saving model to ./result_0.0001_64/epoch_98.h5\n",
            "Epoch 97, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 22s - loss: 6.3255e-04 - accuracy: 0.9997 - val_loss: 0.0683 - val_accuracy: 0.9883 - 22s/epoch - 438ms/step\n",
            "Epoch 99/100\n",
            "Epoch 98, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 5.2652e-04 - accuracy: 0.9997 - val_loss: 0.0688 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "Epoch 100/100\n",
            "Epoch 99, the optimizer state is {'name': 'Adam', 'learning_rate': 1e-04, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 1.7262e-04 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "\n",
            " Test accuracy: 0.9549999833106995\n",
            "0.0005 32\n",
            "Epoch 1/100\n",
            "Epoch 0, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 26s - loss: 0.0280 - accuracy: 0.9900 - val_loss: 10.1521 - val_accuracy: 0.3568 - 26s/epoch - 518ms/step\n",
            "Epoch 2/100\n",
            "Epoch 1, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0468 - accuracy: 0.9862 - val_loss: 0.3250 - val_accuracy: 0.9297 - 10s/epoch - 203ms/step\n",
            "Epoch 3/100\n",
            "Epoch 2, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0308 - accuracy: 0.9894 - val_loss: 0.5181 - val_accuracy: 0.9010 - 10s/epoch - 203ms/step\n",
            "Epoch 4/100\n",
            "Epoch 3, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0386 - accuracy: 0.9906 - val_loss: 0.3464 - val_accuracy: 0.9062 - 10s/epoch - 203ms/step\n",
            "Epoch 5/100\n",
            "Epoch 4, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0320 - accuracy: 0.9937 - val_loss: 0.1306 - val_accuracy: 0.9609 - 10s/epoch - 203ms/step\n",
            "Epoch 6/100\n",
            "Epoch 5, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0402 - accuracy: 0.9906 - val_loss: 0.2928 - val_accuracy: 0.9453 - 10s/epoch - 203ms/step\n",
            "Epoch 7/100\n",
            "Epoch 6, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 11s - loss: 0.0205 - accuracy: 0.9956 - val_loss: 0.0580 - val_accuracy: 0.9844 - 11s/epoch - 224ms/step\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: saving model to ./result_0.0005_32/epoch_8.h5\n",
            "Epoch 7, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 14s - loss: 0.0173 - accuracy: 0.9950 - val_loss: 0.0057 - val_accuracy: 1.0000 - 14s/epoch - 288ms/step\n",
            "Epoch 9/100\n",
            "Epoch 8, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0186 - accuracy: 0.9944 - val_loss: 0.0142 - val_accuracy: 0.9922 - 10s/epoch - 203ms/step\n",
            "Epoch 10/100\n",
            "Epoch 9, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.0594 - val_accuracy: 0.9870 - 10s/epoch - 203ms/step\n",
            "Epoch 11/100\n",
            "Epoch 10, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0183 - accuracy: 0.9937 - val_loss: 0.1510 - val_accuracy: 0.9609 - 10s/epoch - 203ms/step\n",
            "Epoch 12/100\n",
            "Epoch 11, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0214 - accuracy: 0.9931 - val_loss: 4.0233e-04 - val_accuracy: 1.0000 - 10s/epoch - 203ms/step\n",
            "Epoch 13/100\n",
            "Epoch 12, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0134 - accuracy: 0.9944 - val_loss: 0.0086 - val_accuracy: 0.9948 - 10s/epoch - 203ms/step\n",
            "Epoch 14/100\n",
            "Epoch 13, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0275 - accuracy: 0.9944 - val_loss: 0.0396 - val_accuracy: 0.9844 - 10s/epoch - 204ms/step\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: saving model to ./result_0.0005_32/epoch_15.h5\n",
            "Epoch 14, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 14s - loss: 0.0115 - accuracy: 0.9962 - val_loss: 0.0110 - val_accuracy: 0.9948 - 14s/epoch - 280ms/step\n",
            "Epoch 16/100\n",
            "Epoch 15, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0168 - accuracy: 0.9944 - val_loss: 3.6229 - val_accuracy: 0.5781 - 10s/epoch - 203ms/step\n",
            "Epoch 17/100\n",
            "Epoch 16, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 11s - loss: 0.0104 - accuracy: 0.9975 - val_loss: 0.0158 - val_accuracy: 0.9948 - 11s/epoch - 225ms/step\n",
            "Epoch 18/100\n",
            "Epoch 17, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0096 - accuracy: 0.9962 - val_loss: 0.0575 - val_accuracy: 0.9818 - 10s/epoch - 204ms/step\n",
            "Epoch 19/100\n",
            "Epoch 18, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0182 - accuracy: 0.9962 - val_loss: 0.0142 - val_accuracy: 0.9948 - 10s/epoch - 203ms/step\n",
            "Epoch 20/100\n",
            "Epoch 19, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0249 - val_accuracy: 0.9870 - 10s/epoch - 203ms/step\n",
            "Epoch 21/100\n",
            "Epoch 20, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0073 - accuracy: 0.9962 - val_loss: 0.0509 - val_accuracy: 0.9740 - 10s/epoch - 203ms/step\n",
            "Epoch 22/100\n",
            "Epoch 21, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0067 - accuracy: 0.9975 - val_loss: 0.0021 - val_accuracy: 1.0000 - 10s/epoch - 203ms/step\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: saving model to ./result_0.0005_32/epoch_23.h5\n",
            "Epoch 22, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 14s - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.0750 - val_accuracy: 0.9740 - 14s/epoch - 281ms/step\n",
            "Epoch 24/100\n",
            "Epoch 23, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0059 - accuracy: 0.9969 - val_loss: 0.0037 - val_accuracy: 1.0000 - 10s/epoch - 203ms/step\n",
            "Epoch 25/100\n",
            "Epoch 24, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.0030 - val_accuracy: 1.0000 - 10s/epoch - 203ms/step\n",
            "Epoch 26/100\n",
            "Epoch 25, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0748 - val_accuracy: 0.9714 - 10s/epoch - 204ms/step\n",
            "Epoch 27/100\n",
            "Epoch 26, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0278 - val_accuracy: 0.9896 - 10s/epoch - 204ms/step\n",
            "Epoch 28/100\n",
            "Epoch 27, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9922 - 10s/epoch - 203ms/step\n",
            "Epoch 29/100\n",
            "Epoch 28, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0984 - val_accuracy: 0.9661 - 10s/epoch - 203ms/step\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: saving model to ./result_0.0005_32/epoch_30.h5\n",
            "Epoch 29, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 15s - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.0355 - val_accuracy: 0.9922 - 15s/epoch - 298ms/step\n",
            "Epoch 31/100\n",
            "Epoch 30, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0120 - accuracy: 0.9987 - val_loss: 4.9593e-04 - val_accuracy: 1.0000 - 10s/epoch - 203ms/step\n",
            "Epoch 32/100\n",
            "Epoch 31, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 11s - loss: 0.0049 - accuracy: 0.9981 - val_loss: 0.0020 - val_accuracy: 1.0000 - 11s/epoch - 224ms/step\n",
            "Epoch 33/100\n",
            "Epoch 32, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0035 - accuracy: 0.9981 - val_loss: 0.0275 - val_accuracy: 0.9922 - 10s/epoch - 203ms/step\n",
            "Epoch 34/100\n",
            "Epoch 33, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0159 - val_accuracy: 0.9948 - 10s/epoch - 203ms/step\n",
            "Epoch 35/100\n",
            "Epoch 34, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 7.8152e-04 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 0.9896 - 10s/epoch - 203ms/step\n",
            "Epoch 36/100\n",
            "Epoch 35, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0171 - accuracy: 0.9981 - val_loss: 0.0254 - val_accuracy: 0.9896 - 10s/epoch - 203ms/step\n",
            "Epoch 37/100\n",
            "Epoch 36, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0539 - val_accuracy: 0.9766 - 10s/epoch - 203ms/step\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: saving model to ./result_0.0005_32/epoch_38.h5\n",
            "Epoch 37, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 14s - loss: 0.0080 - accuracy: 0.9987 - val_loss: 0.0639 - val_accuracy: 0.9740 - 14s/epoch - 280ms/step\n",
            "Epoch 39/100\n",
            "Epoch 38, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0080 - accuracy: 0.9987 - val_loss: 0.0190 - val_accuracy: 0.9974 - 10s/epoch - 203ms/step\n",
            "Epoch 40/100\n",
            "Epoch 39, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.0387 - val_accuracy: 0.9870 - 10s/epoch - 203ms/step\n",
            "Epoch 41/100\n",
            "Epoch 40, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0232 - accuracy: 0.9956 - val_loss: 189.5861 - val_accuracy: 0.0573 - 10s/epoch - 203ms/step\n",
            "Epoch 42/100\n",
            "Epoch 41, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0132 - accuracy: 0.9969 - val_loss: 8.3964 - val_accuracy: 0.6042 - 10s/epoch - 203ms/step\n",
            "Epoch 43/100\n",
            "Epoch 42, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0092 - accuracy: 0.9981 - val_loss: 0.0532 - val_accuracy: 0.9792 - 10s/epoch - 203ms/step\n",
            "Epoch 44/100\n",
            "Epoch 43, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 11s - loss: 0.0187 - accuracy: 0.9962 - val_loss: 0.0127 - val_accuracy: 0.9948 - 11s/epoch - 224ms/step\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: saving model to ./result_0.0005_32/epoch_45.h5\n",
            "Epoch 44, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 14s - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.1146 - val_accuracy: 0.9609 - 14s/epoch - 278ms/step\n",
            "Epoch 46/100\n",
            "Epoch 45, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0192 - accuracy: 0.9937 - val_loss: 0.0021 - val_accuracy: 1.0000 - 10s/epoch - 203ms/step\n",
            "Epoch 47/100\n",
            "Epoch 46, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0045 - accuracy: 0.9981 - val_loss: 0.0236 - val_accuracy: 0.9896 - 10s/epoch - 203ms/step\n",
            "Epoch 48/100\n",
            "Epoch 47, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0227 - accuracy: 0.9944 - val_loss: 0.0800 - val_accuracy: 0.9661 - 10s/epoch - 203ms/step\n",
            "Epoch 49/100\n",
            "Epoch 48, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.0264 - val_accuracy: 0.9896 - 10s/epoch - 203ms/step\n",
            "Epoch 50/100\n",
            "Epoch 49, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0067 - accuracy: 0.9975 - val_loss: 0.0141 - val_accuracy: 0.9948 - 10s/epoch - 203ms/step\n",
            "Epoch 51/100\n",
            "Epoch 50, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.0773 - val_accuracy: 0.9661 - 10s/epoch - 203ms/step\n",
            "Epoch 52/100\n",
            "Epoch 51, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0126 - val_accuracy: 0.9948 - 10s/epoch - 203ms/step\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: saving model to ./result_0.0005_32/epoch_53.h5\n",
            "Epoch 52, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 14s - loss: 0.0029 - accuracy: 0.9987 - val_loss: 0.0352 - val_accuracy: 0.9870 - 14s/epoch - 280ms/step\n",
            "Epoch 54/100\n",
            "Epoch 53, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.0038 - val_accuracy: 0.9974 - 10s/epoch - 204ms/step\n",
            "Epoch 55/100\n",
            "Epoch 54, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000 - 10s/epoch - 203ms/step\n",
            "Epoch 56/100\n",
            "Epoch 55, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.0133 - val_accuracy: 0.9922 - 10s/epoch - 203ms/step\n",
            "Epoch 57/100\n",
            "Epoch 56, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.0012 - val_accuracy: 1.0000 - 10s/epoch - 203ms/step\n",
            "Epoch 58/100\n",
            "Epoch 57, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0041 - accuracy: 0.9981 - val_loss: 0.0318 - val_accuracy: 0.9870 - 10s/epoch - 203ms/step\n",
            "Epoch 59/100\n",
            "Epoch 58, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000 - 10s/epoch - 203ms/step\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: saving model to ./result_0.0005_32/epoch_60.h5\n",
            "Epoch 59, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 14s - loss: 0.0069 - accuracy: 0.9975 - val_loss: 0.1439 - val_accuracy: 0.9531 - 14s/epoch - 278ms/step\n",
            "Epoch 61/100\n",
            "Epoch 60, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.0151 - val_accuracy: 0.9922 - 10s/epoch - 203ms/step\n",
            "Epoch 62/100\n",
            "Epoch 61, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.1199 - val_accuracy: 0.9661 - 10s/epoch - 203ms/step\n",
            "Epoch 63/100\n",
            "Epoch 62, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0045 - accuracy: 0.9981 - val_loss: 0.1057 - val_accuracy: 0.9714 - 10s/epoch - 203ms/step\n",
            "Epoch 64/100\n",
            "Epoch 63, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.1132 - val_accuracy: 0.9661 - 10s/epoch - 203ms/step\n",
            "Epoch 65/100\n",
            "Epoch 64, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0330 - val_accuracy: 0.9818 - 10s/epoch - 203ms/step\n",
            "Epoch 66/100\n",
            "Epoch 65, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0072 - accuracy: 0.9987 - val_loss: 0.0844 - val_accuracy: 0.9661 - 10s/epoch - 203ms/step\n",
            "Epoch 67/100\n",
            "Epoch 66, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0121 - val_accuracy: 0.9948 - 10s/epoch - 203ms/step\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 00068: saving model to ./result_0.0005_32/epoch_68.h5\n",
            "Epoch 67, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 14s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 0.9922 - 14s/epoch - 279ms/step\n",
            "Epoch 69/100\n",
            "Epoch 68, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0043 - accuracy: 0.9981 - val_loss: 0.0157 - val_accuracy: 0.9922 - 10s/epoch - 203ms/step\n",
            "Epoch 70/100\n",
            "Epoch 69, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.2133 - val_accuracy: 0.9531 - 10s/epoch - 203ms/step\n",
            "Epoch 71/100\n",
            "Epoch 70, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.0300 - val_accuracy: 0.9896 - 10s/epoch - 203ms/step\n",
            "Epoch 72/100\n",
            "Epoch 71, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0875 - val_accuracy: 0.9740 - 10s/epoch - 203ms/step\n",
            "Epoch 73/100\n",
            "Epoch 72, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 7.1436e-04 - accuracy: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.9896 - 10s/epoch - 203ms/step\n",
            "Epoch 74/100\n",
            "Epoch 73, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.0216 - val_accuracy: 0.9948 - 10s/epoch - 203ms/step\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 00075: saving model to ./result_0.0005_32/epoch_75.h5\n",
            "Epoch 74, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 15s - loss: 0.0038 - accuracy: 0.9981 - val_loss: 0.0684 - val_accuracy: 0.9792 - 15s/epoch - 301ms/step\n",
            "Epoch 76/100\n",
            "Epoch 75, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.0390 - val_accuracy: 0.9818 - 10s/epoch - 203ms/step\n",
            "Epoch 77/100\n",
            "Epoch 76, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0124 - val_accuracy: 0.9922 - 10s/epoch - 203ms/step\n",
            "Epoch 78/100\n",
            "Epoch 77, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 7.6291e-04 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000 - 10s/epoch - 203ms/step\n",
            "Epoch 79/100\n",
            "Epoch 78, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.0192 - val_accuracy: 0.9922 - 10s/epoch - 203ms/step\n",
            "Epoch 80/100\n",
            "Epoch 79, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0117 - val_accuracy: 0.9948 - 10s/epoch - 203ms/step\n",
            "Epoch 81/100\n",
            "Epoch 80, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 7.3698e-04 - accuracy: 1.0000 - val_loss: 3.8466e-04 - val_accuracy: 1.0000 - 10s/epoch - 202ms/step\n",
            "Epoch 82/100\n",
            "Epoch 81, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0011 - val_accuracy: 1.0000 - 10s/epoch - 203ms/step\n",
            "Epoch 83/100\n",
            "\n",
            "Epoch 00083: saving model to ./result_0.0005_32/epoch_83.h5\n",
            "Epoch 82, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 14s - loss: 3.9914e-04 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000 - 14s/epoch - 279ms/step\n",
            "Epoch 84/100\n",
            "Epoch 83, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 2.5404e-04 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000 - 10s/epoch - 203ms/step\n",
            "Epoch 85/100\n",
            "Epoch 84, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0074 - val_accuracy: 0.9974 - 10s/epoch - 203ms/step\n",
            "Epoch 86/100\n",
            "Epoch 85, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.0016 - val_accuracy: 1.0000 - 10s/epoch - 203ms/step\n",
            "Epoch 87/100\n",
            "Epoch 86, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 11s - loss: 7.5336e-04 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9974 - 11s/epoch - 224ms/step\n",
            "Epoch 88/100\n",
            "Epoch 87, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 9.4170e-04 - accuracy: 0.9994 - val_loss: 0.0028 - val_accuracy: 0.9974 - 10s/epoch - 203ms/step\n",
            "Epoch 89/100\n",
            "Epoch 88, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0016 - val_accuracy: 1.0000 - 10s/epoch - 203ms/step\n",
            "Epoch 90/100\n",
            "\n",
            "Epoch 00090: saving model to ./result_0.0005_32/epoch_90.h5\n",
            "Epoch 89, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 14s - loss: 2.9785e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000 - 14s/epoch - 287ms/step\n",
            "Epoch 91/100\n",
            "Epoch 90, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0012 - val_accuracy: 1.0000 - 10s/epoch - 203ms/step\n",
            "Epoch 92/100\n",
            "Epoch 91, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.0777 - val_accuracy: 0.9792 - 10s/epoch - 203ms/step\n",
            "Epoch 93/100\n",
            "Epoch 92, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.0632 - val_accuracy: 0.9766 - 10s/epoch - 203ms/step\n",
            "Epoch 94/100\n",
            "Epoch 93, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0775 - val_accuracy: 0.9766 - 10s/epoch - 203ms/step\n",
            "Epoch 95/100\n",
            "Epoch 94, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0092 - accuracy: 0.9987 - val_loss: 0.0901 - val_accuracy: 0.9766 - 10s/epoch - 203ms/step\n",
            "Epoch 96/100\n",
            "Epoch 95, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 6.0575e-04 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 0.9974 - 10s/epoch - 203ms/step\n",
            "Epoch 97/100\n",
            "Epoch 96, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 2.7548e-04 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9974 - 10s/epoch - 203ms/step\n",
            "Epoch 98/100\n",
            "\n",
            "Epoch 00098: saving model to ./result_0.0005_32/epoch_98.h5\n",
            "Epoch 97, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 14s - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0285 - val_accuracy: 0.9896 - 14s/epoch - 280ms/step\n",
            "Epoch 99/100\n",
            "Epoch 98, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.0118 - val_accuracy: 0.9974 - 10s/epoch - 203ms/step\n",
            "Epoch 100/100\n",
            "Epoch 99, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 10s - loss: 0.0100 - accuracy: 0.9975 - val_loss: 0.2586 - val_accuracy: 0.9635 - 10s/epoch - 203ms/step\n",
            "\n",
            " Test accuracy: 0.9466666579246521\n",
            "0.0005 64\n",
            "Epoch 1/100\n",
            "Epoch 0, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 33s - loss: 8.7462e-04 - accuracy: 0.9994 - val_loss: 0.7616 - val_accuracy: 0.8724 - 33s/epoch - 667ms/step\n",
            "Epoch 2/100\n",
            "Epoch 1, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 2.6735e-04 - accuracy: 1.0000 - val_loss: 0.3091 - val_accuracy: 0.9401 - 18s/epoch - 365ms/step\n",
            "Epoch 3/100\n",
            "Epoch 2, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 8.0094e-04 - accuracy: 0.9994 - val_loss: 0.2007 - val_accuracy: 0.9596 - 18s/epoch - 365ms/step\n",
            "Epoch 4/100\n",
            "Epoch 3, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.0777 - val_accuracy: 0.9870 - 18s/epoch - 365ms/step\n",
            "Epoch 5/100\n",
            "Epoch 4, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0584 - val_accuracy: 0.9909 - 18s/epoch - 365ms/step\n",
            "Epoch 6/100\n",
            "Epoch 5, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 5.8088e-04 - accuracy: 0.9997 - val_loss: 0.0621 - val_accuracy: 0.9857 - 18s/epoch - 365ms/step\n",
            "Epoch 7/100\n",
            "Epoch 6, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 7.1436e-04 - accuracy: 0.9997 - val_loss: 0.1187 - val_accuracy: 0.9766 - 18s/epoch - 365ms/step\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: saving model to ./result_0.0005_64/epoch_8.h5\n",
            "Epoch 7, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 22s - loss: 1.1429e-04 - accuracy: 1.0000 - val_loss: 0.0877 - val_accuracy: 0.9831 - 22s/epoch - 443ms/step\n",
            "Epoch 9/100\n",
            "Epoch 8, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.2566 - val_accuracy: 0.9505 - 18s/epoch - 365ms/step\n",
            "Epoch 10/100\n",
            "Epoch 9, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0031 - accuracy: 0.9987 - val_loss: 5.6934 - val_accuracy: 0.5456 - 18s/epoch - 365ms/step\n",
            "Epoch 11/100\n",
            "Epoch 10, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0964 - val_accuracy: 0.9831 - 18s/epoch - 365ms/step\n",
            "Epoch 12/100\n",
            "Epoch 11, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 21s - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0685 - val_accuracy: 0.9909 - 21s/epoch - 413ms/step\n",
            "Epoch 13/100\n",
            "Epoch 12, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0691 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "Epoch 14/100\n",
            "Epoch 13, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 8.8521e-04 - accuracy: 0.9997 - val_loss: 0.0692 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: saving model to ./result_0.0005_64/epoch_15.h5\n",
            "Epoch 14, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 22s - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.2776 - val_accuracy: 0.9518 - 22s/epoch - 439ms/step\n",
            "Epoch 16/100\n",
            "Epoch 15, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.1127 - val_accuracy: 0.9779 - 18s/epoch - 365ms/step\n",
            "Epoch 17/100\n",
            "Epoch 16, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.1297 - val_accuracy: 0.9701 - 18s/epoch - 365ms/step\n",
            "Epoch 18/100\n",
            "Epoch 17, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0029 - accuracy: 0.9987 - val_loss: 0.0649 - val_accuracy: 0.9896 - 18s/epoch - 365ms/step\n",
            "Epoch 19/100\n",
            "Epoch 18, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 7.6188e-04 - accuracy: 1.0000 - val_loss: 0.0706 - val_accuracy: 0.9909 - 18s/epoch - 365ms/step\n",
            "Epoch 20/100\n",
            "Epoch 19, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0732 - val_accuracy: 0.9857 - 18s/epoch - 365ms/step\n",
            "Epoch 21/100\n",
            "Epoch 20, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0948 - val_accuracy: 0.9844 - 18s/epoch - 365ms/step\n",
            "Epoch 22/100\n",
            "Epoch 21, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0788 - val_accuracy: 0.9870 - 18s/epoch - 365ms/step\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: saving model to ./result_0.0005_64/epoch_23.h5\n",
            "Epoch 22, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 23s - loss: 4.3340e-04 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 0.9883 - 23s/epoch - 451ms/step\n",
            "Epoch 24/100\n",
            "Epoch 23, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0976 - val_accuracy: 0.9857 - 18s/epoch - 365ms/step\n",
            "Epoch 25/100\n",
            "Epoch 24, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0058 - accuracy: 0.9994 - val_loss: 0.0810 - val_accuracy: 0.9844 - 18s/epoch - 365ms/step\n",
            "Epoch 26/100\n",
            "Epoch 25, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 6.7675e-04 - accuracy: 0.9997 - val_loss: 0.0812 - val_accuracy: 0.9805 - 18s/epoch - 365ms/step\n",
            "Epoch 27/100\n",
            "Epoch 26, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 5.7673e-04 - accuracy: 0.9997 - val_loss: 0.0789 - val_accuracy: 0.9844 - 18s/epoch - 365ms/step\n",
            "Epoch 28/100\n",
            "Epoch 27, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 1.7085e-04 - accuracy: 1.0000 - val_loss: 0.0773 - val_accuracy: 0.9844 - 18s/epoch - 365ms/step\n",
            "Epoch 29/100\n",
            "Epoch 28, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 8.1764e-04 - accuracy: 0.9997 - val_loss: 0.0770 - val_accuracy: 0.9857 - 18s/epoch - 365ms/step\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: saving model to ./result_0.0005_64/epoch_30.h5\n",
            "Epoch 29, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 22s - loss: 8.2498e-04 - accuracy: 0.9997 - val_loss: 0.0788 - val_accuracy: 0.9870 - 22s/epoch - 440ms/step\n",
            "Epoch 31/100\n",
            "Epoch 30, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0010 - accuracy: 0.9994 - val_loss: 0.0806 - val_accuracy: 0.9870 - 18s/epoch - 365ms/step\n",
            "Epoch 32/100\n",
            "Epoch 31, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 3.9731e-04 - accuracy: 0.9997 - val_loss: 0.0793 - val_accuracy: 0.9870 - 18s/epoch - 365ms/step\n",
            "Epoch 33/100\n",
            "Epoch 32, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0773 - val_accuracy: 0.9870 - 18s/epoch - 365ms/step\n",
            "Epoch 34/100\n",
            "Epoch 33, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 4.6962e-04 - accuracy: 0.9997 - val_loss: 0.0784 - val_accuracy: 0.9870 - 18s/epoch - 365ms/step\n",
            "Epoch 35/100\n",
            "Epoch 34, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 7.7367e-05 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 0.9870 - 18s/epoch - 365ms/step\n",
            "Epoch 36/100\n",
            "Epoch 35, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0017 - accuracy: 0.9991 - val_loss: 0.0989 - val_accuracy: 0.9831 - 18s/epoch - 365ms/step\n",
            "Epoch 37/100\n",
            "Epoch 36, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 1.1324e-04 - accuracy: 1.0000 - val_loss: 0.0866 - val_accuracy: 0.9857 - 18s/epoch - 365ms/step\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: saving model to ./result_0.0005_64/epoch_38.h5\n",
            "Epoch 37, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 22s - loss: 9.2929e-04 - accuracy: 0.9997 - val_loss: 0.0832 - val_accuracy: 0.9883 - 22s/epoch - 441ms/step\n",
            "Epoch 39/100\n",
            "Epoch 38, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 5.4059e-04 - accuracy: 0.9997 - val_loss: 0.0842 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "Epoch 40/100\n",
            "Epoch 39, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 6.4871e-05 - accuracy: 1.0000 - val_loss: 0.0833 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "Epoch 41/100\n",
            "Epoch 40, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 7.7606e-04 - accuracy: 0.9994 - val_loss: 0.0858 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "Epoch 42/100\n",
            "Epoch 41, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.0798 - val_accuracy: 0.9896 - 18s/epoch - 365ms/step\n",
            "Epoch 43/100\n",
            "Epoch 42, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 3.0976e-04 - accuracy: 0.9997 - val_loss: 0.0780 - val_accuracy: 0.9896 - 18s/epoch - 365ms/step\n",
            "Epoch 44/100\n",
            "Epoch 43, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.0798 - val_accuracy: 0.9896 - 18s/epoch - 365ms/step\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: saving model to ./result_0.0005_64/epoch_45.h5\n",
            "Epoch 44, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 22s - loss: 5.7280e-04 - accuracy: 0.9997 - val_loss: 0.0802 - val_accuracy: 0.9896 - 22s/epoch - 441ms/step\n",
            "Epoch 46/100\n",
            "Epoch 45, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0945 - val_accuracy: 0.9896 - 18s/epoch - 365ms/step\n",
            "Epoch 47/100\n",
            "Epoch 46, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 7.0410e-04 - accuracy: 0.9997 - val_loss: 0.0869 - val_accuracy: 0.9870 - 18s/epoch - 365ms/step\n",
            "Epoch 48/100\n",
            "Epoch 47, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 8.2209e-04 - accuracy: 0.9997 - val_loss: 0.0757 - val_accuracy: 0.9896 - 18s/epoch - 365ms/step\n",
            "Epoch 49/100\n",
            "Epoch 48, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 7.5825e-05 - accuracy: 1.0000 - val_loss: 0.0740 - val_accuracy: 0.9896 - 18s/epoch - 365ms/step\n",
            "Epoch 50/100\n",
            "Epoch 49, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 8.7316e-05 - accuracy: 1.0000 - val_loss: 0.0744 - val_accuracy: 0.9896 - 18s/epoch - 365ms/step\n",
            "Epoch 51/100\n",
            "Epoch 50, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 8.2494e-04 - accuracy: 0.9997 - val_loss: 0.0737 - val_accuracy: 0.9896 - 18s/epoch - 365ms/step\n",
            "Epoch 52/100\n",
            "Epoch 51, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 8.2440e-04 - accuracy: 0.9997 - val_loss: 0.0759 - val_accuracy: 0.9896 - 18s/epoch - 364ms/step\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: saving model to ./result_0.0005_64/epoch_53.h5\n",
            "Epoch 52, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 22s - loss: 4.8744e-05 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 0.9883 - 22s/epoch - 440ms/step\n",
            "Epoch 54/100\n",
            "Epoch 53, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 8.9457e-04 - accuracy: 0.9994 - val_loss: 0.0739 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "Epoch 55/100\n",
            "Epoch 54, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 3.5460e-04 - accuracy: 1.0000 - val_loss: 0.0736 - val_accuracy: 0.9896 - 18s/epoch - 365ms/step\n",
            "Epoch 56/100\n",
            "Epoch 55, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 5.1040e-05 - accuracy: 1.0000 - val_loss: 0.0723 - val_accuracy: 0.9896 - 18s/epoch - 365ms/step\n",
            "Epoch 57/100\n",
            "Epoch 56, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 3.6497e-04 - accuracy: 1.0000 - val_loss: 0.0736 - val_accuracy: 0.9896 - 18s/epoch - 365ms/step\n",
            "Epoch 58/100\n",
            "Epoch 57, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 5.0902e-05 - accuracy: 1.0000 - val_loss: 0.0745 - val_accuracy: 0.9896 - 18s/epoch - 365ms/step\n",
            "Epoch 59/100\n",
            "Epoch 58, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 2.8430e-04 - accuracy: 1.0000 - val_loss: 0.0751 - val_accuracy: 0.9883 - 18s/epoch - 365ms/step\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: saving model to ./result_0.0005_64/epoch_60.h5\n",
            "Epoch 59, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 22s - loss: 7.0299e-04 - accuracy: 0.9994 - val_loss: 0.0739 - val_accuracy: 0.9883 - 22s/epoch - 439ms/step\n",
            "Epoch 61/100\n",
            "Epoch 60, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 3.3222e-04 - accuracy: 0.9997 - val_loss: 0.0745 - val_accuracy: 0.9896 - 18s/epoch - 364ms/step\n",
            "Epoch 62/100\n",
            "Epoch 61, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 3.2983e-04 - accuracy: 1.0000 - val_loss: 0.0733 - val_accuracy: 0.9896 - 18s/epoch - 364ms/step\n",
            "Epoch 63/100\n",
            "Epoch 62, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 3.7717e-04 - accuracy: 0.9997 - val_loss: 0.0721 - val_accuracy: 0.9896 - 18s/epoch - 365ms/step\n",
            "Epoch 64/100\n",
            "Epoch 63, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 1.2730e-04 - accuracy: 1.0000 - val_loss: 0.0719 - val_accuracy: 0.9896 - 18s/epoch - 365ms/step\n",
            "Epoch 65/100\n",
            "Epoch 64, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 4.8909e-04 - accuracy: 0.9997 - val_loss: 0.0743 - val_accuracy: 0.9896 - 18s/epoch - 365ms/step\n",
            "Epoch 66/100\n",
            "Epoch 65, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0739 - val_accuracy: 0.9896 - 18s/epoch - 365ms/step\n",
            "Epoch 67/100\n",
            "Epoch 66, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 9.6596e-04 - accuracy: 0.9997 - val_loss: 0.0716 - val_accuracy: 0.9909 - 18s/epoch - 365ms/step\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 00068: saving model to ./result_0.0005_64/epoch_68.h5\n",
            "Epoch 67, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 22s - loss: 7.5308e-04 - accuracy: 0.9994 - val_loss: 0.0747 - val_accuracy: 0.9896 - 22s/epoch - 442ms/step\n",
            "Epoch 69/100\n",
            "Epoch 68, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 21s - loss: 5.4488e-04 - accuracy: 0.9997 - val_loss: 0.0736 - val_accuracy: 0.9909 - 21s/epoch - 413ms/step\n",
            "Epoch 70/100\n",
            "Epoch 69, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 5.5647e-04 - accuracy: 0.9997 - val_loss: 0.0703 - val_accuracy: 0.9909 - 18s/epoch - 364ms/step\n",
            "Epoch 71/100\n",
            "Epoch 70, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 6.3692e-04 - accuracy: 0.9997 - val_loss: 0.0719 - val_accuracy: 0.9909 - 18s/epoch - 365ms/step\n",
            "Epoch 72/100\n",
            "Epoch 71, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 5.7732e-04 - accuracy: 0.9997 - val_loss: 0.0737 - val_accuracy: 0.9870 - 18s/epoch - 364ms/step\n",
            "Epoch 73/100\n",
            "Epoch 72, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 3.5159e-04 - accuracy: 0.9997 - val_loss: 0.0715 - val_accuracy: 0.9909 - 18s/epoch - 365ms/step\n",
            "Epoch 74/100\n",
            "Epoch 73, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 2.9536e-05 - accuracy: 1.0000 - val_loss: 0.0716 - val_accuracy: 0.9909 - 18s/epoch - 365ms/step\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 00075: saving model to ./result_0.0005_64/epoch_75.h5\n",
            "Epoch 74, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 22s - loss: 1.9460e-04 - accuracy: 1.0000 - val_loss: 0.0730 - val_accuracy: 0.9909 - 22s/epoch - 441ms/step\n",
            "Epoch 76/100\n",
            "Epoch 75, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.0748 - val_accuracy: 0.9896 - 18s/epoch - 365ms/step\n",
            "Epoch 77/100\n",
            "Epoch 76, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 7.3808e-05 - accuracy: 1.0000 - val_loss: 0.0715 - val_accuracy: 0.9896 - 18s/epoch - 365ms/step\n",
            "Epoch 78/100\n",
            "Epoch 77, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 4.4353e-04 - accuracy: 0.9997 - val_loss: 0.0673 - val_accuracy: 0.9896 - 18s/epoch - 365ms/step\n",
            "Epoch 79/100\n",
            "Epoch 78, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 1.6910e-04 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 0.9896 - 18s/epoch - 364ms/step\n",
            "Epoch 80/100\n",
            "Epoch 79, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.0702 - val_accuracy: 0.9909 - 18s/epoch - 364ms/step\n",
            "Epoch 81/100\n",
            "Epoch 80, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 6.2004e-04 - accuracy: 0.9997 - val_loss: 0.0689 - val_accuracy: 0.9909 - 18s/epoch - 364ms/step\n",
            "Epoch 82/100\n",
            "Epoch 81, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 1.2424e-04 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 0.9909 - 18s/epoch - 364ms/step\n",
            "Epoch 83/100\n",
            "\n",
            "Epoch 00083: saving model to ./result_0.0005_64/epoch_83.h5\n",
            "Epoch 82, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 22s - loss: 3.9316e-04 - accuracy: 0.9997 - val_loss: 0.0685 - val_accuracy: 0.9909 - 22s/epoch - 440ms/step\n",
            "Epoch 84/100\n",
            "Epoch 83, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 5.1482e-04 - accuracy: 0.9997 - val_loss: 0.0695 - val_accuracy: 0.9909 - 18s/epoch - 364ms/step\n",
            "Epoch 85/100\n",
            "Epoch 84, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 4.6549e-04 - accuracy: 0.9997 - val_loss: 0.0708 - val_accuracy: 0.9909 - 18s/epoch - 365ms/step\n",
            "Epoch 86/100\n",
            "Epoch 85, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 3.8115e-04 - accuracy: 0.9997 - val_loss: 0.0709 - val_accuracy: 0.9909 - 18s/epoch - 365ms/step\n",
            "Epoch 87/100\n",
            "Epoch 86, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 1.4801e-04 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9909 - 18s/epoch - 364ms/step\n",
            "Epoch 88/100\n",
            "Epoch 87, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 6.7265e-04 - accuracy: 0.9997 - val_loss: 0.0698 - val_accuracy: 0.9909 - 18s/epoch - 365ms/step\n",
            "Epoch 89/100\n",
            "Epoch 88, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 4.1771e-05 - accuracy: 1.0000 - val_loss: 0.0693 - val_accuracy: 0.9909 - 18s/epoch - 365ms/step\n",
            "Epoch 90/100\n",
            "\n",
            "Epoch 00090: saving model to ./result_0.0005_64/epoch_90.h5\n",
            "Epoch 89, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 22s - loss: 7.5998e-04 - accuracy: 0.9994 - val_loss: 0.0705 - val_accuracy: 0.9909 - 22s/epoch - 440ms/step\n",
            "Epoch 91/100\n",
            "Epoch 90, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 7.8261e-04 - accuracy: 0.9994 - val_loss: 0.0704 - val_accuracy: 0.9896 - 18s/epoch - 365ms/step\n",
            "Epoch 92/100\n",
            "Epoch 91, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 5.0740e-04 - accuracy: 0.9997 - val_loss: 0.0692 - val_accuracy: 0.9896 - 18s/epoch - 364ms/step\n",
            "Epoch 93/100\n",
            "Epoch 92, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 2.3740e-04 - accuracy: 1.0000 - val_loss: 0.0687 - val_accuracy: 0.9896 - 18s/epoch - 365ms/step\n",
            "Epoch 94/100\n",
            "Epoch 93, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 7.2155e-05 - accuracy: 1.0000 - val_loss: 0.0696 - val_accuracy: 0.9896 - 18s/epoch - 365ms/step\n",
            "Epoch 95/100\n",
            "Epoch 94, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 3.2462e-04 - accuracy: 0.9997 - val_loss: 0.0694 - val_accuracy: 0.9896 - 18s/epoch - 365ms/step\n",
            "Epoch 96/100\n",
            "Epoch 95, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 8.5012e-04 - accuracy: 0.9997 - val_loss: 0.0718 - val_accuracy: 0.9896 - 18s/epoch - 365ms/step\n",
            "Epoch 97/100\n",
            "Epoch 96, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 1.8226e-04 - accuracy: 1.0000 - val_loss: 0.0706 - val_accuracy: 0.9896 - 18s/epoch - 365ms/step\n",
            "Epoch 98/100\n",
            "\n",
            "Epoch 00098: saving model to ./result_0.0005_64/epoch_98.h5\n",
            "Epoch 97, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 22s - loss: 6.9694e-04 - accuracy: 0.9997 - val_loss: 0.0705 - val_accuracy: 0.9896 - 22s/epoch - 440ms/step\n",
            "Epoch 99/100\n",
            "Epoch 98, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 2.7120e-05 - accuracy: 1.0000 - val_loss: 0.0695 - val_accuracy: 0.9896 - 18s/epoch - 364ms/step\n",
            "Epoch 100/100\n",
            "Epoch 99, the optimizer state is {'name': 'Adam', 'learning_rate': 0.0005, 'decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "50/50 - 18s - loss: 4.3524e-04 - accuracy: 0.9997 - val_loss: 0.0676 - val_accuracy: 0.9896 - 18s/epoch - 365ms/step\n",
            "\n",
            " Test accuracy: 0.9108333587646484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "accuracy     = [[], [], [], []]\n",
        "loss         = [[], [], [], []]\n",
        "val_loss     = [[], [], [], []]\n",
        "val_accuracy = [[], [], [], []]\n",
        "\n",
        "\n",
        "for i in range(4):\n",
        "  path = './' + csv_file[i]\n",
        "\n",
        "  with open(path) as f:\n",
        "    myCsv = csv.reader(f)\n",
        "    headers = next(myCsv)\n",
        "    for row in myCsv:\n",
        "      #print(row)\n",
        "      val_accuracy[i].append(float(row[3]))\n",
        "      val_loss[i].append(float(row[4]))\n",
        "      loss[i].append(float(row[2]))\n",
        "      accuracy[i].append(float(row[1]))\n",
        "    \n",
        "    lr, bs =  paras[i]\n",
        "\n",
        "    title = \"ResNet152 with lr = \" + str(lr) + \" & batch_size = \" + str(bs) + \" Accuracy\"\n",
        "    plt.title(title)\n",
        "    plt.plot(np.array(list(range(num_epochs))), np.array(accuracy[i][0:num_epochs]), label = \"accuracy\", linestyle=\"--\")\n",
        "    plt.plot(np.array(list(range(num_epochs))), np.array(val_accuracy[i][:num_epochs]), label = \"val_accuracy\", linestyle=\"-\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vEuz8NgDsbJG",
        "outputId": "85e0f784-eda0-4a77-991c-581591ab9546"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "with open('accuracy_original.csv', 'w', newline='') as acc_file:\n",
        "    writer = csv.writer(acc_file)\n",
        "    for i in range(4):\n",
        "      str1 = 'train accuracy ' + str(i+1)\n",
        "      str2 = 'validation accuracy ' + str(i+1)\n",
        "      str3 = 'test accuracy ' + str(i+1)\n",
        "      str4 = 'prediction error ' + str(i+1)\n",
        "      \n",
        "      list1 = [str1]\n",
        "      list2 = [str2]\n",
        "      list3 = [str3, 0]\n",
        "      list4 = [str4]\n",
        "      list1 = list1 + accuracy[i]\n",
        "      list2 = list2 + val_accuracy[i]\n",
        "      list3[1] = score[i][1]\n",
        "      list4 = list4 + diffr[i]\n",
        "\n",
        "      writer.writerow(list1)\n",
        "      writer.writerow(list2)\n",
        "      writer.writerow(list3)\n",
        "      writer.writerow(list4)\n",
        "\n",
        "      list5 = []\n",
        "      writer.writerow(list5)"
      ],
      "metadata": {
        "id": "neRGVvlOsbmw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"accuracy_original.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "UcRA3dNLXFoP",
        "outputId": "9b32c8e8-c0f2-41b4-fb94-93a1a46c7817"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_b377c2e6-f0f3-4d6c-8f0e-4c99ec6a4081\", \"accuracy_original.csv\", 13802)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#暫時關閉"
      ],
      "metadata": {
        "id": "TTLgmXC_vkVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "model = tf.keras.models.load_model(\"model_ResNet152_20211224_0706_20epochs.h5\")\n",
        "model\n",
        "'''"
      ],
      "metadata": {
        "id": "X2Z6vzZ-iLWZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "eea709c7-662e-4067-926d-b8af77a4c7ee"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nmodel = tf.keras.models.load_model(\"model_ResNet152_20211224_0706_20epochs.h5\")\\nmodel\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "checkpointer = ModelCheckpoint(filepath='model_ResNet152_20211224_0859_22epochs.h5', verbose=1, save_best_only=True)#filepath保存模型的路徑\n",
        "history = model.fit(train_xx, train_yy, batch_size=32, epochs=2, callbacks=[mc, csv_logger, print_lr()], steps_per_epoch=4, validation_data=(val_xx, val_yy), validation_steps=2, verbose=2, shuffle=True) # 改成epochs=100\n",
        "'''"
      ],
      "metadata": {
        "id": "RID2Cf-xu3KI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f5ec6667-1505-432f-b6df-f4d46e052f4f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\\ncheckpointer = ModelCheckpoint(filepath='model_ResNet152_20211224_0859_22epochs.h5', verbose=1, save_best_only=True)#filepath保存模型的路徑\\nhistory = model.fit(train_xx, train_yy, batch_size=32, epochs=2, callbacks=[mc, csv_logger, print_lr()], steps_per_epoch=4, validation_data=(val_xx, val_yy), validation_steps=2, verbose=2, shuffle=True) # 改成epochs=100\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss: 0.0495 - accuracy: 0.9922 - val_loss: 0.3787 - val_accuracy: 0.9062 "
      ],
      "metadata": {
        "id": "wIFheQf_vSW-"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}